"""
–£–õ–£–ß–®–ï–ù–ù–´–ô —Å–µ—Ä–≤–∏—Å –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏ –∏ —Ä–µ–≥–∏—Å—Ç—Ä–∞
–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã —Å –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º–∏ –∑–Ω–∞–∫–∞–º–∏ –∏ –∑–∞–ø—è—Ç—ã–º–∏
"""

import logging
import re
from typing import Dict, Any, List
import os

# –î–ª—è BERT-–º–æ–¥–µ–ª–∏
try:
    from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification
    import torch
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False
    pipeline = None
    AutoTokenizer = None
    AutoModelForTokenClassification = None


class PunctuationService:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π —Å–µ—Ä–≤–∏—Å –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏ –∏ —Ä–µ–≥–∏—Å—Ç—Ä–∞ –≤ —Ç–µ–∫—Å—Ç–µ"""
    
    def __init__(self, config: Any):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ —Å–µ—Ä–≤–∏—Å–∞ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π BERT

        Args:
            config: –û–±—ä–µ–∫—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        """
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.model = None
        self.tokenizer = None
        self.bert_pipeline = None

        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏
        punctuation_config = config.get("punctuation", {})
        self.mode = punctuation_config.get('mode', 'conservative')
        self.cache_dir = punctuation_config.get('cache_dir', './cache/punctuation')

        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
        model_config = punctuation_config.get('model', {})
        self.model_provider = model_config.get('provider', 'none')
        self.model_name = model_config.get('name', 'DeepPavlov/bert-base-cased-sentence')
        self.use_gpu = model_config.get('use_gpu', False)

        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–∞–≤–∏–ª
        rules_config = punctuation_config.get('rules', {})
        self.aggressive_commas = rules_config.get('aggressive_commas', False)
        self.fix_abbreviations = rules_config.get('fix_abbreviations', True)

        self.logger.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏ (—Ä–µ–∂–∏–º: {self.mode}, –º–æ–¥–µ–ª—å: {self.model_provider})")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è BERT-–º–æ–¥–µ–ª–∏ –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ
        if self.model_provider != 'none':
            self._init_bert_model()

    def _init_bert_model(self):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è BERT-–º–æ–¥–µ–ª–∏ –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏
        """
        if not TRANSFORMERS_AVAILABLE:
            self.logger.warning("Transformers –Ω–µ –¥–æ—Å—Ç—É–ø–Ω—ã, –æ—Ç–∫–ª—é—á–∞–µ–º BERT-–º–æ–¥–µ–ª—å")
            self.model_provider = 'none'
            return

        try:
            self.logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ BERT-–º–æ–¥–µ–ª–∏: {self.model_name}")

            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –∫—ç—à–∞ –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
            os.makedirs(self.cache_dir, exist_ok=True)

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
            device = 0 if self.use_gpu and torch.cuda.is_available() else -1

            self.bert_pipeline = pipeline(
                "token-classification",
                model=self.model_name,
                tokenizer=self.model_name,
                device=device,
                cache_dir=self.cache_dir,
                aggregation_strategy="simple"
            )

            self.logger.info("‚úÖ BERT-–º–æ–¥–µ–ª—å –¥–ª—è –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")

        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è BERT-–º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {str(e).split(':')[0]}")
            self.logger.info("–ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ rule-based —Ä–µ–∂–∏–º (–Ω–æ—Ä–º–∞–ª—å–Ω–æ)")
            self.model_provider = 'none'

    def restore_punctuation(self, text) -> str:
        """
        –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é –∏ —Ä–µ–≥–∏—Å—Ç—Ä –≤ —Ç–µ–∫—Å—Ç–µ
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏ (—Å—Ç—Ä–æ–∫–∞ –∏–ª–∏ —Å–ª–æ–≤–∞—Ä—å)
            
        Returns:
            –¢–µ–∫—Å—Ç —Å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–π –ø—É–Ω–∫—Ç—É–∞—Ü–∏–µ–π –∏ —Ä–µ–≥–∏—Å—Ç—Ä–æ–º
        """
        try:
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–ª—É—á–∞–π –∫–æ–≥–¥–∞ –ø–µ—Ä–µ–¥–∞–Ω —Å–ª–æ–≤–∞—Ä—å
            if isinstance(text, dict):
                text = text.get("text", "")
            
            text = str(text)  # –ü—Ä–∏–≤–æ–¥–∏–º –∫ —Å—Ç—Ä–æ–∫–µ
            
            if not text.strip():
                return text
            
            self.logger.info(f"–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏ –¥–ª—è —Ç–µ–∫—Å—Ç–∞ –¥–ª–∏–Ω–æ–π {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # –ü–†–ï–î–í–ê–†–ò–¢–ï–õ–¨–ù–ê–Ø –æ—á–∏—Å—Ç–∫–∞ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –æ—Ç –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
            text = self._pre_clean_text(text)
            
            # –í—ã–±–∏—Ä–∞–µ–º –º–µ—Ç–æ–¥ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞
            if self.mode == 'bert' and self.bert_pipeline:
                # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: BERT-–º–æ–¥–µ–ª—å –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞
                self.logger.info("–ò—Å–ø–æ–ª—å–∑—É–µ–º BERT-–º–æ–¥–µ–ª—å –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏")
                return self._restore_with_bert(text)
            elif self.mode == 'conservative':
                return self._restore_conservative(text)
            elif self.mode == 'improved':
                return self._restore_improved_fixed(text)
            else:
                # Fallback –Ω–∞ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π
                return self._restore_conservative(text)

        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
            return self._restore_basic_safe(text)

    def _restore_with_bert(self, text: str) -> str:
        """
        –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏ —Å –ø–æ–º–æ—â—å—é BERT-–º–æ–¥–µ–ª–∏

        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏

        Returns:
            –¢–µ–∫—Å—Ç —Å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–π –ø—É–Ω–∫—Ç—É–∞—Ü–∏–µ–π
        """
        try:
            if not self.bert_pipeline:
                self.logger.warning("BERT-–º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ rule-based")
                return self._restore_improved_fixed(text)

            self.logger.info("üîß BERT: –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏")

            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ—Ç –º–æ–¥–µ–ª–∏
            predictions = self.bert_pipeline(text)

            # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫ —Ç–µ–∫—Å—Ç—É
            result = self._apply_bert_predictions(text, predictions)

            # –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            result = self._post_process_bert_result(result)

            self.logger.info("‚úÖ BERT: –ü—É–Ω–∫—Ç—É–∞—Ü–∏—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")
            return result

        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ BERT-–≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è: {e}")
            # Fallback –Ω–∞ —É–ª—É—á—à–µ–Ω–Ω—ã–π rule-based
            return self._restore_improved_fixed(text)

    def _apply_bert_predictions(self, text: str, predictions: List[Dict]) -> str:
        """
        –ü—Ä–∏–º–µ–Ω—è–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è BERT-–º–æ–¥–µ–ª–∏ –∫ —Ç–µ–∫—Å—Ç—É

        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            predictions: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏

        Returns:
            –¢–µ–∫—Å—Ç —Å –ø—Ä–∏–º–µ–Ω–µ–Ω–Ω—ã–º–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏
        """
        if not predictions:
            return text

        result = text
        offset = 0  # –°–º–µ—â–µ–Ω–∏–µ –∏–∑-–∑–∞ –≤—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤

        for pred in predictions:
            if pred['entity'] in ['PERIOD', 'COMMA', 'QUESTION', 'EXCLAMATION']:
                # –ü–æ–ª—É—á–∞–µ–º –ø–æ–∑–∏—Ü–∏—é –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏
                start_pos = pred['start'] + offset

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–∏–º–≤–æ–ª –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏
                if pred['entity'] == 'PERIOD':
                    punct = '.'
                elif pred['entity'] == 'COMMA':
                    punct = ','
                elif pred['entity'] == 'QUESTION':
                    punct = '?'
                elif pred['entity'] == 'EXCLAMATION':
                    punct = '!'
                else:
                    continue

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–∞ —ç—Ç–æ–π –ø–æ–∑–∏—Ü–∏–∏ –µ—â–µ –Ω–µ—Ç –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏
                if start_pos < len(result) and result[start_pos] not in '.!?,;:':
                    # –í—Å—Ç–∞–≤–ª—è–µ–º —Å–∏–º–≤–æ–ª
                    result = result[:start_pos] + punct + result[start_pos:]
                    offset += 1

        return result

    def _post_process_bert_result(self, text: str) -> str:
        """
        –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ BERT-–º–æ–¥–µ–ª–∏

        Args:
            text: –†–µ–∑—É–ª—å—Ç–∞—Ç BERT-–æ–±—Ä–∞–±–æ—Ç–∫–∏

        Returns:
            –§–∏–Ω–∞–ª—å–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –¥–≤–æ–π–Ω—ã–µ –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        text = re.sub(r'([.!?])\1+', r'\1', text)

        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        text = re.sub(r'\s*([.!?,;:])\s*', r'\1 ', text)

        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞—á–∞–ª–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π (–∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è)
        sentences = re.split(r'([.!?]\s*)', text)
        result_sentences = []

        for i, sentence in enumerate(sentences):
            if i % 2 == 0:  # –¢–µ–∫—Å—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                sentence = sentence.strip()
                if sentence:
                    sentence = sentence[0].upper() + sentence[1:]
            result_sentences.append(sentence)

        result = ''.join(result_sentences)

        # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞
        result = self._post_process_safe(result)

        return result

    def _pre_clean_text(self, text: str) -> str:
        """
        –ü–†–ï–î–í–ê–†–ò–¢–ï–õ–¨–ù–ê–Ø –æ—á–∏—Å—Ç–∫–∞ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –æ—Ç –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ Whisper
        –ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã –î–û –æ—Å–Ω–æ–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        
        Args:
            text: –°—ã—Ä–æ–π —Ç–µ–∫—Å—Ç –æ—Ç Whisper
            
        Returns:
            –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è –≤ –Ω–∞—á–∞–ª–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤
        text = re.sub(r'^\s*[.,!?]+\s*', '', text)  # –£–±–∏—Ä–∞–µ–º –∑–Ω–∞–∫–∏ –≤ –Ω–∞—á–∞–ª–µ
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º —Ä–∞–∑–æ—Ä–≤–∞–Ω–Ω—ã–µ —Å–ª–æ–≤–∞ —Ç–∏–ø–∞ "–í. –ø—Ä–∏–Ω—Ü–∏–ø–µ"
        text = re.sub(r'\b([–ê-–Ø–Å])\.\s+([–∞-—è—ë])', r'\1 \2', text)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã–µ —Ç–æ—á–∫–∞–º–∏
        # "–±–ª–∞–≥–æ–¥–∞—Ä—è –Ω–∞—à–µ–º—É –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—é. –≤. –ø—Ä–∏–Ω—Ü–∏–ø–µ" ‚Üí "–±–ª–∞–≥–æ–¥–∞—Ä—è –Ω–∞—à–µ–º—É –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—é –≤ –ø—Ä–∏–Ω—Ü–∏–ø–µ"
        words = text.split()
        cleaned_words = []
        
        for i, word in enumerate(words):
            # –ï—Å–ª–∏ —ç—Ç–æ –∫–æ—Ä–æ—Ç–∫–æ–µ —Å–ª–æ–≤–æ —Å —Ç–æ—á–∫–æ–π –≤ –∫–æ–Ω—Ü–µ
            if len(word) <= 3 and word.endswith('.') and i < len(words) - 1:
                # –ò —Å–ª–µ–¥—É—é—â–µ–µ —Å–ª–æ–≤–æ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã
                next_word = words[i + 1] if i + 1 < len(words) else ""
                if next_word and next_word[0].islower():
                    # –£–±–∏—Ä–∞–µ–º —Ç–æ—á–∫—É –∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º
                    cleaned_words.append(word[:-1])
                    continue
            
            cleaned_words.append(word)
        
        return " ".join(cleaned_words)
    
    def _restore_conservative(self, text: str) -> str:
        """
        –ö–û–ù–°–ï–†–í–ê–¢–ò–í–ù–û–ï –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏
        –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –Ω–∞–¥—ë–∂–Ω–æ—Å—Ç–∏
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            
        Returns:
            –¢–µ–∫—Å—Ç —Å –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–æ–π –ø—É–Ω–∫—Ç—É–∞—Ü–∏–µ–π
        """
        try:
            # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç
            result = text.strip()
            
            if not result:
                return result
            
            # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ –ª–æ–≥–∏—á–µ—Å–∫–∏–º –ø–∞—É–∑–∞–º
            sentences = self._split_into_sentences_safe(result)
            
            processed_sentences = []
            for sentence in sentences:
                sentence = sentence.strip()
                if sentence:
                    # –ö–∞–ø–∏—Ç–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—É—é –±—É–∫–≤—É
                    sentence = sentence[0].upper() + sentence[1:] if len(sentence) > 1 else sentence.upper()
                    
                    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –¢–æ–ª—å–∫–æ –æ—á–µ–≤–∏–¥–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã
                    if self._is_clear_question(sentence):
                        if not sentence.endswith('?'):
                            sentence += '?'
                    else:
                        # –û–±—ã—á–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è - —Ç–æ–ª—å–∫–æ —Ç–æ—á–∫–∞
                        if not sentence.endswith(('.', '!', '?')):
                            sentence += '.'
                    
                    processed_sentences.append(sentence)
            
            result = " ".join(processed_sentences)
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –±–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
            result = self._post_process_safe(result)
            
            return result
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
            return self._restore_basic_safe(text)
    
    def _restore_improved_fixed(self, text: str) -> str:
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ï —É–ª—É—á—à–µ–Ω–Ω–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            
        Returns:
            –¢–µ–∫—Å—Ç —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏
        """
        try:
            # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç
            result = text.strip()
            
            if not result:
                return result
            
            # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
            sentences = self._split_into_sentences_safe(result)
            
            processed_sentences = []
            for sentence in sentences:
                sentence = sentence.strip()
                if sentence:
                    # –ö–∞–ø–∏—Ç–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—É—é –±—É–∫–≤—É
                    sentence = sentence[0].upper() + sentence[1:] if len(sentence) > 1 else sentence.upper()
                    
                    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞ –≤–æ–ø—Ä–æ—Å–æ–≤
                    if self._is_clear_question(sentence):
                        if not sentence.endswith('?'):
                            sentence += '?'
                    elif self._is_exclamation(sentence):
                        if not sentence.endswith('!'):
                            sentence += '!'
                    else:
                        # –û–±—ã—á–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                        if not sentence.endswith(('.', '!', '?')):
                            sentence += '.'
                    
                    processed_sentences.append(sentence)
            
            result = " ".join(processed_sentences)
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è —Ä–∞—Å—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø—è—Ç—ã—Ö
            result = self._add_commas_safe(result)
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
            result = self._post_process_safe(result)
            
            return result
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
            return self._restore_conservative(text)
    
    def _is_clear_question(self, sentence: str) -> bool:
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–û: –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–æ–º
        
        Args:
            sentence: –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            True –µ—Å–ª–∏ —ç—Ç–æ —è–≤–Ω–æ –≤–æ–ø—Ä–æ—Å
        """
        sentence_lower = sentence.lower().strip()
        
        # –í–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ –ù–ê–ß–ò–ù–ê–Æ–¢ –≤–æ–ø—Ä–æ—Å
        question_starters = [
            "–∫–∞–∫", "—á—Ç–æ", "–∫—Ç–æ", "–≥–¥–µ", "–∫–æ–≥–¥–∞", "–ø–æ—á–µ–º—É", "–∑–∞—á–µ–º", 
            "–∫—É–¥–∞", "–æ—Ç–∫—É–¥–∞", "–∫–∞–∫–æ–π", "–∫–∞–∫–∞—è", "–∫–∞–∫–æ–µ", "–∫–∞–∫–∏–µ",
            "—Å–∫–æ–ª—å–∫–æ", "—á–µ–π", "—á—å—è", "—á—å—ë", "—á—å–∏"
        ]
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–∞—á–∞–ª–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        for starter in question_starters:
            if sentence_lower.startswith(starter + " "):
                return True
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤–æ–ø—Ä–æ—Å–æ–≤
        question_patterns = [
            r"^–∞\s+",  # "–∞ —á—Ç–æ", "–∞ –∫–∞–∫"
            r"^–Ω–µ—É–∂–µ–ª–∏\s+",
            r"^—Ä–∞–∑–≤–µ\s+",
            r"^–ª–∏\s+",
            r"^–º–æ–∂–µ—Ç\s+–ª–∏\s+",
            r"^–º–æ–∂–Ω–æ\s+–ª–∏\s+"
        ]
        
        for pattern in question_patterns:
            if re.match(pattern, sentence_lower):
                return True
        
        return False
    
    def _is_exclamation(self, sentence: str) -> bool:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –≤–æ—Å–∫–ª–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º
        
        Args:
            sentence: –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            True –µ—Å–ª–∏ —ç—Ç–æ –≤–æ—Å–∫–ª–∏—Ü–∞–Ω–∏–µ
        """
        sentence_lower = sentence.lower()
        
        exclamatory_words = [
            "—Å—Ç–æ–ø", "—Ö–≤–∞—Ç–∏—Ç", "–ø—Ä–µ–∫—Ä–∞—Ç–∏", "–æ—Å—Ç–∞–Ω–æ–≤–∏—Å—å", "—É–∂–∞—Å", 
            "–±–æ–∂–µ", "–≤–∞—É", "–∫–ª–∞—Å—Å", "—Å—É–ø–µ—Ä", "–æ—Ç–ª–∏—á–Ω–æ", "–±—Ä–∞–≤–æ"
        ]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤–æ—Å–∫–ª–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö —Å–ª–æ–≤
        for word in exclamatory_words:
            if word in sentence_lower:
                return True
        
        return False
    
    def _add_commas_safe(self, text: str) -> str:
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–û: –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è —Ä–∞—Å—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø—è—Ç—ã—Ö
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            
        Returns:
            –¢–µ–∫—Å—Ç —Å –±–µ–∑–æ–ø–∞—Å–Ω–æ —Ä–∞—Å—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –∑–∞–ø—è—Ç—ã–º–∏
        """
        # –£–ë–†–ê–ù–û: –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –¥–ª—è —Å–æ—é–∑–æ–≤ "–∏", "–∞", "–Ω–æ"
        
        # –¢–æ–ª—å–∫–æ –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –ø–æ—Å–ª–µ –≤–≤–æ–¥–Ω—ã—Ö —Å–ª–æ–≤
        introductory_words = [
            "–Ω–∞–ø—Ä–∏–º–µ—Ä", "–∫–æ–Ω–µ—á–Ω–æ", "–∏—Ç–∞–∫", "–ø–æ—ç—Ç–æ–º—É", "—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ",
            "–≤–æ-–ø–µ—Ä–≤—ã—Ö", "–≤–æ-–≤—Ç–æ—Ä—ã—Ö", "–≤-—Ç—Ä–µ—Ç—å–∏—Ö", "–Ω–∞–∫–æ–Ω–µ—Ü", "–∫—Ä–æ–º–µ —Ç–æ–≥–æ"
        ]
        
        for word in introductory_words:
            # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø—è—Ç—É—é –ø–æ—Å–ª–µ –≤–≤–æ–¥–Ω–æ–≥–æ —Å–ª–æ–≤–∞ –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
            pattern = r'(\. |\A)(' + re.escape(word) + r') ([–∞-—è—ë–ê-–Ø–Å])'
            replacement = r'\1\2, \3'
            text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)
        
        # –ó–∞–ø—è—Ç–∞—è –ø–µ—Ä–µ–¥ "–∫–æ—Ç–æ—Ä—ã–π", "–∫–æ—Ç–æ—Ä–∞—è", "–∫–æ—Ç–æ—Ä–æ–µ" (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Å—Ç–æ–∏–º–µ–Ω–∏—è)
        relative_pronouns = ["–∫–æ—Ç–æ—Ä—ã–π", "–∫–æ—Ç–æ—Ä–∞—è", "–∫–æ—Ç–æ—Ä–æ–µ", "–∫–æ—Ç–æ—Ä—ã–µ"]
        for pronoun in relative_pronouns:
            pattern = r'([–∞-—è—ë–ê-–Ø–Å]{3,}) (' + pronoun + r') '
            replacement = r'\1, \2 '
            text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)
        
        return text
    
    def _split_into_sentences_safe(self, text: str) -> List[str]:
        """
        –£–õ–£–ß–®–ï–ù–ù–û–ï —Ä–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –∫–æ—Ä–æ—Ç–∫–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã, –∏–∑–±–µ–≥–∞–µ—Ç "–í. –ü—Ä–∏–Ω—Ü–∏–ø–µ"
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        """
        # –ü—Ä–æ—Å—Ç–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –∏ –¥–ª–∏–Ω–µ
        sentence_breaks = [
            "–≤–æ-–ø–µ—Ä–≤—ã—Ö", "–≤–æ-–≤—Ç–æ—Ä—ã—Ö", "–≤-—Ç—Ä–µ—Ç—å–∏—Ö", "–Ω–∞–∫–æ–Ω–µ—Ü",
            "–∏—Ç–∞–∫", "–ø–æ—ç—Ç–æ–º—É", "–æ–¥–Ω–∞–∫–æ", "—Ç–µ–º –Ω–µ –º–µ–Ω–µ–µ"
        ]
        
        words = text.split()
        sentences = []
        current_sentence = []
        
        for i, word in enumerate(words):
            current_sentence.append(word)
            
            # –£–õ–£–ß–®–ï–ù–û: –±–æ–ª–µ–µ —É–º–Ω—ã–µ —É—Å–ª–æ–≤–∏—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è
            should_break = (
                len(current_sentence) > 15 or  # –£–≤–µ–ª–∏—á–∏–ª–∏ –ª–∏–º–∏—Ç
                (word.lower() in sentence_breaks and len(current_sentence) > 5) or  # –ú–∏–Ω–∏–º—É–º 5 —Å–ª–æ–≤
                (i < len(words) - 1 and words[i + 1].lower() in sentence_breaks and len(current_sentence) > 5)
            )
            
            # –ù–û–í–û–ï: –ù–ï —Ä–∞–∑–±–∏–≤–∞–µ–º –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã (–∏–∑–±–µ–≥–∞–µ–º "–í. –ü—Ä–∏–Ω—Ü–∏–ø–µ")
            if should_break and len(current_sentence) > 6:  # –ú–∏–Ω–∏–º—É–º 6 —Å–ª–æ–≤ –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è
                sentences.append(" ".join(current_sentence))
                current_sentence = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —Å–ª–æ–≤–∞
        if current_sentence:
            sentences.append(" ".join(current_sentence))
        
        # –ù–û–í–û–ï: –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        merged_sentences = []
        for sentence in sentences:
            # –ï—Å–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–æ–µ (1-2 —Å–ª–æ–≤–∞) - –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º
            if len(sentence.split()) <= 2 and merged_sentences:
                merged_sentences[-1] += " " + sentence.lower()
            else:
                merged_sentences.append(sentence)
        
        return merged_sentences
    
    def _post_process_safe(self, text: str) -> str:
        """
        –ë–ï–ó–û–ü–ê–°–ù–ê–Ø –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            
        Returns:
            –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
        text = re.sub(r'\s+', ' ', text)
        
        # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –ø–µ—Ä–µ–¥ –∑–Ω–∞–∫–∞–º–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        text = re.sub(r'\s+([.!?,:;])', r'\1', text)
        
        # –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û –ê–ì–†–ï–°–°–ò–í–ù–ê–Ø –æ—á–∏—Å—Ç–∫–∞ –¥—É–±–ª–µ–π (–≤—Å–µ –ø—Ä–æ–±–ª–µ–º—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è)
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: ? > ! > . > ,
        text = re.sub(r'[,!.]*\?', '?', text)       # –õ—é–±—ã–µ –∑–Ω–∞–∫–∏ + ? ‚Üí —Ç–æ–ª—å–∫–æ ?
        text = re.sub(r'[,.]*!(?!\?)', '!', text)   # –õ—é–±—ã–µ –∑–Ω–∞–∫–∏ + ! ‚Üí —Ç–æ–ª—å–∫–æ ! (–Ω–æ –Ω–µ !?)
        text = re.sub(r'![.]', '!', text)           # ! + —Ç–æ—á–∫–∞ ‚Üí —Ç–æ–ª—å–∫–æ !
        text = re.sub(r'[.]+', '.', text)           # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ç–æ—á–∫–∏ ‚Üí –æ–¥–Ω–∞
        text = re.sub(r'[,]+', ',', text)           # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∑–∞–ø—è—Ç—ã–µ ‚Üí –æ–¥–Ω–∞
        
        # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–ª—É—á–∞–∏ –∏–∑ –ø—Ä–∏–º–µ—Ä–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        text = re.sub(r',\?', '?', text)            # ,? ‚Üí ?
        text = re.sub(r'\.\?', '?', text)           # .? ‚Üí ?
        text = re.sub(r'!\.$', '!', text)           # !. –≤ –∫–æ–Ω—Ü–µ ‚Üí !
        text = re.sub(r',\.$', '.', text)           # ,. –≤ –∫–æ–Ω—Ü–µ ‚Üí .
        
        # –û—á–∏—Å—Ç–∫–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –æ—Ç –ø–∞—É–∑
        text = re.sub(r'\.\s*,', '.', text)         # –¢–æ—á–∫–∞ –∑–∞–ø—è—Ç–∞—è ‚Üí —Ç–æ—á–∫–∞
        text = re.sub(r',\s*\.', '.', text)         # –ó–∞–ø—è—Ç–∞—è —Ç–æ—á–∫–∞ ‚Üí —Ç–æ—á–∫–∞
        
        # –£–±–∏—Ä–∞–µ–º –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è –ø–æ—Å–ª–µ –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–ª–æ–≤ (–í. –ü—Ä–∏–Ω—Ü–∏–ø–µ ‚Üí –í –ø—Ä–∏–Ω—Ü–∏–ø–µ)
        text = re.sub(r'\b([–ê-–Ø–Å])\.\s+([–∞-—è—ë])', r'\1 \2', text)

        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã –ø–æ—Å–ª–µ –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        text = re.sub(r'([.!?])([–ê-–ØA-Z])', r'\1 \2', text)

        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–≤—ã—á–∫–∏ –∏ —Ç–∏—Ä–µ
        text = self._fix_quotes_and_dashes(text)

        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—é —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
        text = self._fix_transliteration(text)

        # –§–ò–ù–ê–õ–¨–ù–ê–Ø –û–ß–ò–°–¢–ö–ê: —É–±–∏—Ä–∞–µ–º –≤—Å–µ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        text = re.sub(r'\s+', ' ', text)  # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã ‚Üí –æ–¥–∏–Ω –ø—Ä–æ–±–µ–ª
        text = text.strip()               # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ

        return text
    
    def _fix_quotes_and_dashes(self, text: str) -> str:
        """
        –ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –∫–∞–≤—ã—á–∫–∏ –∏ —Ç–∏—Ä–µ –Ω–∞ —Ç–∏–ø–æ–≥—Ä–∞—Ñ—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã

        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç

        Returns:
            –¢–µ–∫—Å—Ç —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –∫–∞–≤—ã—á–∫–∞–º–∏ –∏ —Ç–∏—Ä–µ
        """
        try:
            # –ü—Ä—è–º—ã–µ –∫–∞–≤—ã—á–∫–∏ –Ω–∞ –µ–ª–æ—á–∫–∏
            text = re.sub(r'"([^"]*)"', r'¬´\1¬ª', text)

            # –û–¥–∏–Ω–∞—Ä–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏ –Ω–∞ –ª–∞–ø–∫–∏
            text = re.sub(r"'([^']*)'", r'‚Äπ\1‚Ä∫', text)

            # –ú–∏–Ω—É—Å –Ω–∞ –¥–ª–∏–Ω–Ω–æ–µ —Ç–∏—Ä–µ
            text = re.sub(r'\s+-\s+', ' ‚Äî ', text)

            # –¢—Ä–∏ —Ç–æ—á–∫–∏ –Ω–∞ –º–Ω–æ–≥–æ—Ç–æ—á–∏–µ
            text = re.sub(r'\.\.\.', '‚Ä¶', text)

            return text

        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–∞–≤—ã—á–µ–∫ –∏ —Ç–∏—Ä–µ: {e}")
            return text

    def _fix_transliteration(self, text: str) -> str:
        """
        –ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—é —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤

        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç

        Returns:
            –¢–µ–∫—Å—Ç —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–π —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–µ–π
        """
        try:
            # –¢–µ—Ä–º–∏–Ω—ã –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
            translit_fixes = {
                # MLX-Whisper –≤–º–µ—Å—Ç–æ MLXWishper
                r'\bMLXWishper\b': 'MLX-Whisper',
                r'\bLarge V3\b': 'large-v3',
                r'\b–≥–∏—Ç—Ö–∞–±\b': 'GitHub',
                r'\bGitHub\b': 'GitHub',  # —É–∂–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ
                r'\b–ø—Ä–∏–ª–æ–∂—É—Ö–∞\b': '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ',

                # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è
                r'\b—Ä–∏—Ç–º–µ\b': 'README.md',
                r'\b—Ä–∏–¥–º–∏\b': 'README.md',
                r'\b–∏–≥–Ω–æ—Ä\b': '.gitignore',
                r'\b–∫–∏—Ç –∏–≥–Ω–æ—Ä\b': '.gitignore',
                r'\b–≥–∏–¥ –∏–≥–Ω–æ—Ä\b': '.gitignore',

                # –ù–∞–∑–≤–∞–Ω–∏—è
                r'\bMacBook\b': 'MacBook',
                r'\bmacOS\b': 'macOS',
                r'\bApple\b': 'Apple',

                # –û–±—â–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
                r'\b–º–æ–∂–µ—à—å\b': '–º–æ–∂–µ—à—å',
                r'\b–º–æ–∂–µ—Ç—à—å\b': '–º–æ–∂–µ—à—å'
            }

            for pattern, replacement in translit_fixes.items():
                text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)

            return text

        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏: {e}")
            return text

    def process_text(self, text: str) -> str:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ —Å –ø—É–Ω–∫—Ç—É–∞—Ü–∏–µ–π

        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç

        Returns:
            –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        if not text or not text.strip():
            return text

        try:
            # –û—Å–Ω–æ–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
            result = self.restore_punctuation(text)

            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞
            result = self._post_process_safe(result)

            return result

        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
            return self._restore_basic_safe(text)

    def _restore_basic_safe(self, text: str) -> str:
        """
        –ë–ê–ó–û–í–ê–Ø –±–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–æ–∫

        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç

        Returns:
            –¢–µ–∫—Å—Ç —Å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
        """
        try:
            result = text.strip()

            if not result:
                return result

            # –¢–æ–ª—å–∫–æ –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–≤–æ–π –±—É–∫–≤—ã –∏ —Ç–æ—á–∫–∞ –≤ –∫–æ–Ω—Ü–µ
            if result:
                result = result[0].upper() + result[1:] if len(result) > 1 else result.upper()

                if not result.endswith(('.', '!', '?')):
                    result += '.'

            return result

        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –±–∞–∑–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
            return text
